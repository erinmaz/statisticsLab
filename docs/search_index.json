<<<<<<< Updated upstream
[["lab-3-correlation.html", "Chapter 3 Lab 3: Correlation 3.1 General Goals 3.2 R 3.3 Excel 3.4 SPSS 3.5 JAMOVI", " Chapter 3 Lab 3: Correlation If  we choose a group of social phenomena with no antecedent knowledge of the causation or absence of causation among them, then the calculation of correlation coefficients, total or partial, will not advance us a step toward evaluating the importance of the causes at work. Sir Ronald Fisher In lecture and in the textbook, we have been discussing the idea of correlation. This is the idea that two things that we measure can be somehow related to one another. For example, your personal happiness, which we could try to measure say with a questionnaire, might be related to other things in your life that we could also measure, such as number of close friends, yearly salary, how much chocolate you have in your bedroom, or how many times you have said the word Nintendo in your life. Some of the relationships that we can measure are meaningful, and might reflect a causal relationship where one thing causes a change in another thing. Some of the relationships are spurious, and do not reflect a causal relationship. In this lab you will learn how to compute correlations between two variables in software, and then ask some questions about the correlations that you observe. 3.1 General Goals Compute Pearsons r between two variables using software Discuss the possible meaning of correlations that you observe 3.1.1 Important Info We use data from the World Happiness Report. A .csv of the data can be found here: WHR2018.csv 3.2 R In this lab we use explore to explore correlations between any two variables, and also show how to do a regression line. There will be three main parts. Getting r to compute the correlation, and looking at the data using scatter plots. Well look at some correlations from the World Happiness Report. Then youll look at correlations using data we collect from ourselves. It will be fun. 3.2.1 cor for correlation R has the cor function for computing Pearsons r between any two variables. In fact this same function computes other versions of correlation, but well skip those here. To use the function you just need two variables with numbers in them like this: x &lt;- c(1,3,2,5,4,6,5,8,9) y &lt;- c(6,5,8,7,9,7,8,10,13) cor(x,y) ## [1] 0.76539 Well, that was easy. 3.2.1.1 scatterplots Lets take our silly example, and plot the data in a scatter plot using ggplot2, and lets also return the correlation and print it on the scatter plot. Remember, ggplot2 wants the data in a data.frame, so we first put our x and y variables in a data frame. library(ggplot2) # create data frame for plotting my_df &lt;- data.frame(x,y) # plot it ggplot(my_df, aes(x=x,y=y))+ geom_point()+ geom_text(aes(label = round(cor(x,y), digits=2), y=12, x=2 )) Wow, were moving fast here. 3.2.1.2 lots of scatterplots Before we move on to real data, lets look at some fake data first. Often we will have many measures of X and Y, split between a few different conditions, for example, A, B, C, and D. Lets make some fake data for X and Y, for each condition A, B, C, and D, and then use facet_wrapping to look at four scatter plots all at once x&lt;-rnorm(40,0,1) y&lt;-rnorm(40,0,1) conditions&lt;-rep(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;), each=10) all_df &lt;- data.frame(conditions, x, y) ggplot(all_df, aes(x=x,y=y))+ geom_point()+ facet_wrap(~conditions) 3.2.1.3 computing the correlations all at once Weve seen how we can make four graphs at once. Facet_wrap will always try to make as many graphs as there are individual conditions in the column variable. In this case there are four, so it makes four. Notice, the scatter plots dont show the correlation (r) values. Getting these numbers on there is possible, but we have to calculate them first. Well leave it to you to Google how to do this, if its something you want to do. Instead, what we will do is make a table of the correlations in addition to the scatter plot. We again use dplyr to do this: OK, we are basically ready to turn to some real data and ask if there are correlations between interesting variablesYou will find that there are some But before we do that, we do one more thing. This will help you become a little bit more skeptical of these correlations. 3.2.1.4 Chance correlations As you learned from the textbook. We can find correlations by chance alone, even when there is no true correlation between the variables. For example, if we sampled randomly into x, and then sampled some numbers randomly into y. We know they arent related, because we randomly sampled the numbers. However, doing this creates some correlations some of the time just by chance. You can demonstrate this to yourself with the following code. Its a repeat of what we already saw, jut with a few more conditions added. Lets look at 20 conditions, with random numbers for x and y in each. For each, sample size will be 10. Well make the fake data, then make a big graph to look at all. And, even though we get to regression later in the lab, Ill put the best fit line onto each scatter plot, so you can see the correlations. x&lt;-rnorm(10*20,0,1) y&lt;-rnorm(10*20,0,1) conditions&lt;-rep(1:20, each=10) all_df &lt;- data.frame(conditions, x, y) ggplot(all_df, aes(x=x,y=y))+ geom_point()+ geom_smooth(method=lm, se=FALSE)+ facet_wrap(~conditions)+ theme_classic() ## `geom_smooth()` using formula &#39;y ~ x&#39; You can see that the slope of the blue line is not always flat. Sometimes it looks like there is a correlation, when we know there shouldnt be. You can keep re-doing this graph, by re-knitting your r Markdown document, or by pressing the little green play button. This is basically you simulating the outcomes as many times as you press the button. The point is, now you know you can find correlations by chance. So, in the next section, you should always wonder if the correlations you find reflect meaningful association between the x and y variable, or could have just occurred by chance. 3.2.2 World Happiness Report Lets take a look at some correlations in real data. We are going to look at responses to a questionnaire about happiness that was sent around the world, from the world happiness report 3.2.2.1 Load the data We load the data into a data frame. Reminder, the following assumes that you have downloaded the RMarkdownsLab.zip file which contains the data file in the data folder. library(data.table) whr_data &lt;- fread(&#39;data/WHR2018.csv&#39;) You can also load the data using the following URL library(data.table) whr_data &lt;- fread(&quot;https://raw.githubusercontent.com/CrumpLab/statisticsLab/master/data/WHR2018.csv&quot;) 3.2.2.2 Look at the data library(summarytools) view(dfSummary(whr_data)) You should be able to see that there is data for many different countries, across a few different years. There are lots of different kinds of measures, and each are given a name. Ill show you some examples of asking questions about correlations with this data, then you get to ask and answer your own questions. 3.2.2.3 My Question #1 For the year 2017 only, does a countrys measure for Freedom to make life choices correlate with that countrys measure for \" Confidence in national government\"? Lets find out. We calculate the correlation, and then we make the scatter plot. cor(whr_data$`Freedom to make life choices`, whr_data$`Confidence in national government`) ## [1] NA ggplot(whr_data, aes(x=`Freedom to make life choices`, y=`Confidence in national government`))+ geom_point()+ theme_classic() ## Warning: Removed 167 rows containing missing values (geom_point). Interesting, what happened here? We can see some dots, but the correlation was NA (meaning undefined). This occurred because there are some missing data points in the data. We can remove all the rows with missing data first, then do the correlation. We will do this a couple steps, first creating our own data.frame with only the numbers we want to analyse. We can select the columns we want to keep using select. Then we use filter to remove the rows with NAs. library(dplyr) smaller_df &lt;- whr_data %&gt;% select(country, `Freedom to make life choices`, `Confidence in national government`) %&gt;% filter(!is.na(`Freedom to make life choices`), !is.na(`Confidence in national government`)) cor(smaller_df$`Freedom to make life choices`, smaller_df$`Confidence in national government`) ## [1] 0.4080963 Now we see the correlation is .408. Although the scatter plot shows the dots are everywhere, it generally shows that as Freedom to make life choices increases in a country, that countrys confidence in their national government also increase. This is a positive correlation. Lets do this again and add the best fit line, so the trend is more clear, we use geom_smooth(method=lm, se=FALSE). I also change the alpha value of the dots so they blend it bit, and you can see more of them. # select DVs and filter for NAs smaller_df &lt;- whr_data %&gt;% select(country, `Freedom to make life choices`, `Confidence in national government`) %&gt;% filter(!is.na(`Freedom to make life choices`), !is.na(`Confidence in national government`)) # calcualte correlation cor(smaller_df$`Freedom to make life choices`, smaller_df$`Confidence in national government`) ## [1] 0.4080963 # plot the data with best fit line ggplot(smaller_df, aes(x=`Freedom to make life choices`, y=`Confidence in national government`))+ geom_point(alpha=.5)+ geom_smooth(method=lm, se=FALSE)+ theme_classic() ## `geom_smooth()` using formula &#39;y ~ x&#39; 3.2.2.4 My Question #2 After all that work, we can now speedily answer more questions. For example, what is the relationship between positive affect in a country and negative affect in a country. I wouldnt be surprised if there was a negative correlation here: when positive feelings generally go up, shouldnt negative feelings generally go down? To answer this question, we just copy paste the last code block, and change the DVs to be Positive affect, and Negative affect # select DVs and filter for NAs smaller_df &lt;- whr_data %&gt;% select(country, `Positive affect`, `Negative affect`) %&gt;% filter(!is.na(`Positive affect`), !is.na(`Negative affect`)) # calcualte correlation cor(smaller_df$`Positive affect`, smaller_df$`Negative affect`) ## [1] -0.3841123 # plot the data with best fit line ggplot(smaller_df, aes(x=`Positive affect`, y=`Negative affect`))+ geom_point(alpha=.5)+ geom_smooth(method=lm, se=FALSE)+ theme_classic() ## `geom_smooth()` using formula &#39;y ~ x&#39; Bam, there we have it. As positive affect goes up, negative affect goes down. A negative correlation. 3.2.3 Generalization Exercise This generalization exercise will explore the idea that correlations between two measures can arise by chance alone. There are two questions to answer. For each question you will be sampling random numbers from uniform distribution. To conduct the estimate, you will be running a simulation 100 times. The questions are: Estimate the range (minimum and maximum) of correlations (using pearonss r) that could occur by chance between two variables with n=10. Estimate the range (minimum and maximum) of correlations (using pearonss r) that could occur bychance between two variables with n = 100. Use these tips to answer the question. Tip 1: You can use the runif() function to sample random numbers between a minimum value, and maximum value. The example below sample 10 (n=10) random numbers between the range 0 (min = 0) and 10 (max=10). Everytime you run this code, the 10 values in x will be re-sampled, and will be 10 new random numbers x &lt;- runif(n=10, min=0, max=10) Tip 2: You can compute the correlation between two sets of random numbers, by first sampling random numbers into each variable, and then running the cor() function. x &lt;- runif(n=10, min=0, max=10) y &lt;- runif(n=10, min=0, max=10) cor(x,y) ## [1] -0.3059606 Running the above code will give different values for the correlation each time, because the numbers in x and y are always randomly different. We might expect that because x and y are chosen randomly that there should be a 0 correlation. However, what we see is that random sampling can produce fake correlations just by chance alone. We want to estimate the range of correlations that chance can produce. Tip 3: One way to estimate the range of correlations that chance can produce is to repeat the above code many times. For example, if you ran the above code 100 times, you could save the correlations each time, then look at the smallest and largest correlation. This would be an estimate of the range of correlations that can be produced by chance. How can you repeat the above code many times to solve this problem? We can do this using a for loop. The code below shows how to repeat everything inside the for loop 100 times. The variable i is an index, that goes from 1 to 100. The saved_value variable starts out as an empty variable, and then we put a value into it (at index position i, from 1 to 100). In this code, we put the sum of the products of x and y into the saved_value variable. At the end of the simulation, the save_value variable contains 100 numbers. The min() and max() functions are used to find the minimum and maximum values for each of the 100 simulations. You should be able to modify this code by replacing sum(x*y) with cor(x,y). Doing this will allow you to run the simulation 100 times, and find the minimum correlation and maximum correlation that arises by chance. This will be estimate for question 1. To provide an estimate for question 2, you will need to change n=10 to n=100. saved_value &lt;- c() #make an empty variable for (i in 1:100){ x &lt;- runif(n=10, min=0, max=10) y &lt;- runif(n=10, min=0, max=10) saved_value[i] &lt;- sum(x*y) } min(saved_value) ## [1] 113.0171 max(saved_value) ## [1] 517.7462 3.2.4 Writing assignment Answer the following questions with complete sentences. When you have finished everything. Knit the document and hand in your stuff (you can submit your .RMD file to blackboard if it does not knit.) Imagine a researcher found a positive correlation between two variables, and reported that the r value was +.3. One possibility is that there is a true correlation between these two variables. Discuss one alternative possibility that would also explain the observation of +.3 value between the variables. Explain the difference between a correlation of r = .3 and r = .7. What does a larger value of r represent? Explain the difference between a correlation of r = .5, and r = -.5. 3.3 Excel How to do it in Excel 3.4 SPSS In this lab, we will use SPSS to calculate the correlation coefficient. We will focus on the most commonly used Pearsons coefficient, r. We will learn how to: Calculate the Pearsons r correlation coefficient for bivariate data Produce a correlation matrix, reporting Pearsons r for more than two variables at a time Produce a scatterplot Split a data file for further analysis Lets first begin with a short data set we will enter into a new SPSS data spreadsheet. Remember, in order to calculate a correlation, you need to have bivariate data; that is, you must have at least two variables, x and y. You can have more than two variables, in which case we can calculate a correlation matrix, as indicated in the section that follows. 3.4.1 Correlation Coefficient for Bivariate Data: Two Variables Lets use the following data set: {x= 1, 3, 2, 5, 4, 6, 5, 8, 9} {y= 6, 5, 8, 7, 9, 7, 8, 10, 13}. Notice there are two variables, x and y. Enter these into SPSS and name them appropriately. Next, click Analyze, then Correlate, then Bivariate: The next window will ask you to select variables to correlate. Since we have two (x and y) move them both from the left-hand field to the right-hand field using the arrow. Notice that in this window, Pearson is selected. This is the default setting (and the one we want), but notice there are other ways to calculate the correlation between variables. We will stick with Pearsons correlation coefficient for this course. Now, click OK. SPSS will produce an output table containing the correlation coefficient requested. Notice that the table is redundant; it gives us the correlation between x and y, the correlation between y and x, the correlation between x and itself, and the correlation between y and itself. Any variable correlated with itself will result in an r of 1. The Pearson r correlation between variables x and y is .765. 3.4.2 Correlation Matrix In the event that you have more than two variables in your spreadsheet, and would like to evaluate correlations between several variables taken two at a time, you need not re-run the correlations in SPSS repeatedly. You can, in fact, enter multiple variables into the correlation window and obtain a correlation matrixa table showing every possible bivariate correlation amongst a group of variables. To illustrate how this is done, lets add a new variable to our existing spreadsheet: variable z, {z= 1, 4, 2, 9, 5, 7, 12, 5, 3} From here, go to Analyze, then Correlate, then Bivariate: Next, you will encounter the window that asks you to indicate which variables to correlate. Select all three variables (x, y, and z) and move them to the right-hand field using the arrow. Click OK. SPSS will produce an output table that contains correlations for every pairing of our three variables, along with the correlations of each variable with itself. According to this output: The correlation coefficient between variables x and y is .765 The correlation coefficient between variables x and z is .294 The correlation coefficient between variables y and z is -.080 3.4.3 Correlation and Scatterplots To accompany the calculation of the correlation coefficient, the scatterplot is the relevant visualization tool. Lets use data from The World Happiness Report, a questionnaire about happiness. Here is a link to the file named WHR2018.sav. Using this data, lets answer the following question: does a countrys measure for Freedom to make life choices correlate with that countrys measure for Confidence in national government? Lets find the correlation coefficient between these variables first. Go to Analyze, then Correlate, then Bivariate: Next, a window will appear asking for the variables to be correlated. Go through the list on the left and find Freedom to make life choices as well as Confidence in national government. Move both of these variables to the field on the right using the arrow. Click OK. SPSS will produce a correlation table. Based on this output, the correlation between Freedom to make life choices and Confidence in national government is .408. Lets continue to create the scatterplot for this data. Go to Graphs, then Legacy Dialogs, then Scatter In the next window, choose Simple, then Define: Next, move your two variables (Freedom to make life choices and Confidence in national government) into the x-axis and y-axis fields. Again, it does not matter which variable goes where, for now. Click OK. SPSS will produce a scatterplot of your data, as follows: You can keep this scatterplot as it is, or, you can edit it to include a straight line that best fits the data points. This line is known as the best-fitting line as it minimizes the distance from it to all the data. To edit the scatterplot double click on the graph and a window labeled Chart Editor should appear: In this window, find the button at the top that reads Fit Line at Total when you hover your mouse over it. Below, I have highlighted it for clarity: Press this button and you will see a new menu. Make sure Linear is selected and click Apply. Next, exit from the Chart Editor. This means you will hit the X in the corner of the window. You will find that the graph in your output window has now updated and has a line drawn on it. This scatterplot is very important. The distance between the line and the data points is indicative of the strength of the correlation coefficient; they are directly related. For example, if the data were more clustered or tighter to the line, the correlation would be stronger. If the data points are more spread out and far from the line, the correlation is weaker. 3.4.4 Splitting a File What if we asked the question: for the year 2017 only, does a countrys measure for Freedom to make life choices correlate with that countrys measure for Confidence in national government? Notice that this question is asking us to find the correlation between the same two variables we used in the previous example, but only in the case where the year is 2017. To acheive this, were going to utilize a function called splitting. Splitting takes the file as a whole, and sets it up so that every analysis is done on some subset of the data. For example, if we split our data by year and calculate a correlation coefficient, SPSS will find Pearson r for only 2017, and another for only 2016, and so on. In order to split the data, we go to the top menu and choose Data, then Split file In the next window, you must select Organize output by groups and then specify which variable will be used to split the data. Select year and move it to the right-hand field using the arrow. Click OK. Notice that this will cause the output window to produce some text indicating that you have split your file. You can ignore this and go back to your data window. From here, any analysis you choose to do will be done separately for each years worth of data. Lets calculate the correlation coefficient, as usual. Click Analyze, then Correlate, then Bivariate: In the next window, select the variables to be used (they will be the same as in the last example). Click OK. Notice that in the output window you will see a bunch of correlation tables (13 of them to be exact), one for each year. Scroll down and find the table with the heading year = 2017. Thats the table we need in order to answer our question: This table indicates that, if we only look at the year 2017, the correlation coefficient between Freedom to make life choices and Confidence in national government is .442. It is VERY important to remember that once you have split a file, every analysis that follows the split will be done on the split variable. If you want to go back to performing analyses and calculating statistics for the data as a whole, you must UNSPLIT your data file (or undo the split). To do this, go to Data, then Split file Then make sure to select Analyze all cases, do not create groups and click OK. 3.4.5 Practice Problems For the year 2005 ONLY, find the correlation between perceptions of corruption and positive affect. Create a scatterplot to visualize this relationship. What are your conclusions about the relationship between affect and perceived corruption? Is this surprising to you? What has happened to log GDP (consider this a measure of GDP) in the United States ONLY with time (as the year has increased)? Explain this relationship and provide a scatterplot. Which country (or countries) have seen a more consistent and strong increase in log GDP over time? Which country (or countries) have seen a decrease over time? 3.5 JAMOVI This section is copied almost verbatim, with some editorial changes, from Answering questions with data: The lab manual for R, Excel, SPSS and JAMOVI, Lab 3, Section 3.4, SPSS, according to its CC license. Thank you to Crump, Krishnan, Volz, &amp; Chavarga (2018). In this lab, we will use jamovi to calculate the correlation coefficient. We will focus on the most commonly used Pearsons coefficient, r. We will learn how to: Calculate the Pearsons r correlation coefficient for bivariate data Produce a correlation matrix, reporting Pearsons r for more than two variables at a time Produce a scatterplot Applying a filter to the data set for further analysis Lets first begin with a short data set we will enter into a new jamovi data spreadsheet. Remember, in order to calculate a correlation, you need to have bivariate data; that is, you must have at least two variables, x and y. You can have more than two variables, in which case we can calculate a correlation matrix, as indicated in the section that follows. 3.5.1 Correlation Coefficient for Bivariate Data: Two Variables Lets use the following data set: {x= 1, 3, 2, 5, 4, 6, 5, 8, 9} {y= 6, 5, 8, 7, 9, 7, 8, 10, 13}. Notice there are two variables, x and y. Enter these into jamovi, name them appropriately, and be sure to indicate, in the Analyze, that these data are measured on a continuous scale. (REMEMBER: One assumption of Pearsons correlation is that the variables are measured on at least an interval scale. That means you should not use Pearsons correlation with variables that are measured on an ordinal scale. Spearmans correlation may be helpful if you have variables measured on an ordinal scale.) Remember to use the upward facing arrow or the Settings button to close the Analyze pop-up window. Next, click Analyses, Regression, and Correlation Matrix: In the pop-up window, you will select variables to correlate. Since we have two (x and y) move them both from the left-hand field to the right-hand field by highlighting them and using the arrow. Notice that in this window, Pearson is selected. This is the default setting (and the one we want), but notice there are other ways to calculate the correlation between variables. We will stick with Pearsons correlation coefficient for now. In the Results panel on the left, jamovi will produce an output table containing the correlation coefficient requested. (If you are familiar with SPSS, you may notice that the jamovi table is unlike the SPSS table in that the jamovi correlation matrix does not have the redundant information in the top and bottom triangles of the matrix; jamovi gives us only the correlation between x and y in the bottom portion of the table. Note: Any variable correlated with itself will result in an r of 1.) The Pearson r correlation between variables x and y is .765. 3.5.2 Correlation Matrix In the event that you have more than two variables in your spreadsheet, and would like to evaluate correlations between several variables taken two at a time, you need not re-run the correlations in jamovi repeatedly. You can, in fact, enter multiple variables into the correlation window and obtain a correlation matrixa table showing every possible bivariate correlation amongst a group of variables. To illustrate how this is done, lets add a new variable to our existing spreadsheet: variable z, {z= 1, 4, 2, 9, 5, 7, 12, 5, 3}. From here, go to Analyses, then Regression, and then Correlation Matrix: Next, you will encounter the window that asks you to indicate which variables to correlate. Select all three variables (x, y, and z) by highlighting them, and move them to the right-hand field using the arrow. jamovi will produce an output table in the Results panel to the right that contains correlations for every pairing of our three variables. You should see three correlation coefficients and three associated p-values. According to this output: The correlation coefficient between variables x and y is .765; that is, Pearsons r for variables x and y is .765. The correlation coefficient between variables x and z is .294; Pearsons r for x and z is .294. The correlation coefficient between variables y and z is -.080; Pearsons r for y and z is -.080. To further our understanding of these correlation coefficients, we should also look to the p-values associated with each coefficient to decide if the correlation is significant or non-significant. Pearsons r for variables x and y is .765. The p-value is .02 which is less than a conventional alpha level of .05, so we would consider this result to be significant. We might write: A Pearsons correlation was performed, and variables x and y were found to be significantly correlated, r = .77, p = .02. Pearsons r for x and z is .294. The p-value is .44 which is greater than a conventional alpha level of .05, so we would consider this result to be non-significant. We might write: A Pearsons correlation was performed, and no significant correlation was found between variables x and z, r = .29, p &gt; .05. Pearsons r for y and z is -.080. The p-value is .84 which is greater than a conventional alpha level of .05, so we would consider this result to be non-significant. We might write: A Pearsons correlation was performed, and no significant correlation was found between variables y and z, r = -.08, p &gt; .05. 3.5.3 Correlation and Scatterplots To accompany the calculation of the correlation coefficient, the scatterplot is the relevant visualization tool. Lets use data from EngageNS. Using this data, lets answer the following question: Does Number of hours per week spent working at main job correlate with Home activity participation on a typical day: Playing computer games? Lets find the correlation coefficient between these variables first. Go to Analyses, then Regression, and then Correlation Matrix: Next, a window will appear asking for the variables to be correlated. Use the search function to speed up your identification of those variables. Rather than scrolling through all of the variables in the list on the left, look into the Data Dictionary to find the variable names and search for them. Move both of these variables to the field on the right using the arrow. In the Results panel, jamovi will produce a correlation table. Based on this output, the correlation between WORKHR and HM_CGAME is -.042. The negative sign simply indicates that as the scores on one variable increase, the scores on the other variable decrease; the variables are negatively correlated. Looking at the p-value, we see it is .001, which is less than our commonly used alpha levels. This correlation is significant. We might communicate this information like this: A Pearsons correlation analysis was performed, and a significant negative correlation was found between Number of hours per week spent working at main job and Home activity participation on a typical day: Playing computer games, r = -.04, p = .001. 3.5.3.1 Adding the Scatterplot module to jamovi Before you can request a scatterplot in jamovi, you must add Scatterplot as a module. To do so, click on the addition sign which is white with a blue trim that has the word Modules under the sign. Click jamovi library. Under the Available tab, you should see a module called scatr. Click to INSTALL it. When it is installed, it will appear in your Exploration menu. 3.5.3.2 Getting a visual of the correlation Lets continue to create the scatterplot for this data. Go to Analyses, then Exploration, and then Scatterplot. In the next window, choose Simple, then Define: Next, move your two variables (WORKHR and HM_CGAMES) into the x-axis and y-axis fields. Again, it does not matter which variable goes where, for now. (Remember to use the search function to speed up your search for the variables to include.) In the Results panel, jamovi will produce a scatterplot of your data, as follows: You can keep this scatterplot as it is, or, you can edit it to include a straight line that best fits the data points. This line is known as the best-fitting line as it minimizes the distance from it to all the data. To include the line of best fit, click on Linear under the Regression Line heading. You will find that the graph in your Results panel has now updated and has a line drawn on it. This line of best fit on the scatterplot is barely visible. Typically, the distance between the line and the data points is indicative of the strength of the correlation coefficient; they are directly related. For example, if the data were more clustered or tighter to the line, the correlation would be stronger. If the data points are more spread out and far from the line, the correlation is weaker. In this case, although there are many data points clustered around the line, we also see there are a number of data points that are quite far from the line. This is a moderate correlation. We also see that this negative correlation is depicted by a line that falls to the left (i.e., a line with a negative slope). 3.5.4 Applying a Filter What if we asked the question: For residents of the Antigonish and Guysborough regions only, does Number of hours per week spent working at main job correlate with Home activity participation on a typical day: Playing computer games? Notice that this question is asking us to find the correlation between the same two variables we used in the previous example, but only in the case where the REGION is equal to 4. To achieve this, were going to utilize a function called filtering. Filtering the data set makes only those cases that meet our criteria available for use in the analysis to be run. For example, if we filter our data by region and calculate a correlation coefficient, jamovi will find Pearson r for only Antigonish and Guysborough, and not for other regions. In order to filter the data, we go to the top menu and choose Data and then Filter. In the next window, you must set up the filter; indicate which cases will be used. Under Filter 1, click on the formula editor, the fx button. Double click on the variable name (REGION), and it will be incorporated into the filter. Then, use two equal signs, and enter the code for the region of interest (4). Notice that this will cause a new column in the spreadsheet wherein a green checkmark indicates the case/participant will be included in the analysis and a red x indicates the case/participant will be excluded from the analysis. From here, any analysis you choose to do will be done for only the cases match the filter. Lets calculate the correlation coefficient, as usual. Click Analyses, then Regression, and then Correlation Matrix: In the next window, select the variables to be used (they will be the same as in the last example). Notice that in the output now shows a correlation matrix with different results than you saw when you ran the correlation with the entire data set: This table indicates that, if we only look at the Antigonish-Guysborough region, the correlation coefficient between between WORKHR and HM_CGAME is .012 and the p-value is .80. Comparing this p-value to an alpha level of .05, we would say this correlation is non-significant. Again, you may want to inspect the scatterplot to get a visual representation of this correlation coefficient for the data collected from participants in the Antigonish-Guysborough region. Challenge: Give the creation of this scatterplot a try on your own. See if your graph matches the one depicted below. 3.5.5 Removing the Filter It is VERY important to remember that once you have applied a filter, every analysis will be done on the split variable. If you want to go back to performing analyses and calculating statistics for the data as a whole, you must delete the filter. To do this, you can highlight the column showing the filter in the spreadsheet, go to Data, and then Delete. You will be prompted with a question to verify that you want to delete the filter. Click Yes. 3.5.6 Homework Look at participants reported number of close friends and their reported time spent socializing with friends. Are these scores correlated? If so, report r and whether the correlation is significant or non-signifcant? Apply a filter so that you are looking at only the data for participants whose main activity is going to school (Hint: Use the data dictionary to figure out how participants main activities were coded.). Now, run the same correlation you looked at in #1. Are number of close friends and reported time spent socializing with friends correlated for students? Is the correlation significant? Compare these results to the results in #1. Is the correlation between number of close friends and reported time spent socializing with friends stronger or weaker for students than it is for Nova Scotians? 3.5.7 Practice Problems Use the EngageNS data to answer the following questions: Construct a scatterplot using FRIENDS on the x-axis and SOC_FRND on the y-axis to depict the results you found for the last homework question. Can you run a Pearsons correlation analysis on the following pairs of variables? Why or why not? SEX and SLEEP? COMP_TIME and SLEEP? MAINACT and EDUCAT? Run the correlation analysis for any set(s) of variables you determined to be appropriate for using Pearsons correlation. Report the correlation coefficient. Is it considered statistically significant? Write your results following the APA rules discussed below. Some formatting guidelines for writing results sections: All of the numbers are rounded to two decimal places, but if your p-value was .0001, it would be okay to write p &lt; .001. Italicize symbols such as p and t. There are spaces on either side of =, &gt;, or &lt; symbols. Construct the scatterplot for any set(s) of variables you determined to be appropriate for using Pearsons correlation. What do you notice about the scatterplot? Does the slope increase or decrease? Do the dots closely follow the line of best fit? TBD: questions based on PSYC 291 survey / may want to move some from Lab 7 The follwoing three questions are copied verbatim from Answering questions with data: The lab manual for R, Excel, SPSS and JAMOVI, Lab 3, Section 3.2.4, SPSS, according to its CC license. Thank you to Crump, Krishnan, Volz, &amp; Chavarga (2018). Imagine a researcher found a positive correlation between two variables, and reported that the r value was +.3. One possibility is that there is a true correlation between these two variables. Discuss one alternative possibility that would also explain the observation of +.3 value between the variables. Explain the difference between a correlation of r = .3 and r = .7. What does a larger value of r represent? Explain the difference between a correlation of r = .5, and r = -.5. "]]
=======
<<<<<<< HEAD
[["index.html", "Answering questions with data: Lab Manual Preface 0.1 Important notes", " Answering questions with data: Lab Manual Matthew J. C. Crump, Anjali Krishnan, Stephen Volz, and Alla Chavarga Adapted for PSYC 292, St. Francis Xavier University, by Erin L. Mazerolle, Sherry Neville-MacLean, Christine D. Lomore, and Margaret Vail. Last Compiled 2021-07-12 Preface This is the companion lab to our free introductory statistics for undergraduates in psychology textbook, Answering questions with data. This lab manual involves step by-step tutorials to solve data-analysis problems in software. We use open-data sets that are usually paired with a primary research article. Each lab has a separate guide for solving the problems in R &amp; R-studio, Excel, SPSS, and JAMOVI. The manual is a free and open resource. See below for more information about copying, making change, or contributing to the lab manual. 0.1 Important notes This lab manual is released under a creative commons licence CC BY-SA 4.0. Click the link to read more about the license, or read more below in the license section. This lab manual is part of a larger OER course package for teaching undergraduate statistics in Psychology. Team members include, Matthew Crump, Alla Chavarga, Anjali Krishnan, Jeffrey Suzuki, and Stephen Volz. As this OER comes together, we will be providing a course website, written in R Markdown, as well as slide decks for the lectures (these will be more fully available by the end of fall 2018). As a result, this textbook, the lab manual, the course website, and the slide decks will all be free, under a creative commons license. The source code for all material is contained in the GitHub repositories for each, and they are a written in R-markdown, so they are relatively easy to copy and edit. Have Fun! 0.1.1 Attributions and Versions First Draft (version 0.9 = August 15th, 2018) This was the version we used to adapt the lab manual. That project can be found here. It was authored by Matt Crump (R exercises), Anjali Krishnan (JAMOVI exercises), Stephen Volz (EXCEL exercises), and Alla Chavarga (SPSS exercises). Labs 6, 7, and 8 were adapted and expanded from Open Stats Labs. Thanks to Open Stats Labs (Dr. Kevin P. McIntyre) for their fantastic work. Version 1.0 = April, 2021 This version was our first edit of the lab manual for PSYC 292 at StFX (Winter 2021), and was completed by Erin Mazerolle and Sherry Neville-MacLean. The changes were mainly focused on the SPSS sections of Labs 1, 2, 3, 6, and 7, and in particular, the homework questions. We also added Lab 12. In progress: Version 2.0. Last Compiled: 2021-07-12 We are currently working on updating the lab manual to include JAMOVI activities that will use in PSYC 292 at StFX. 0.1.2 CC BY-SA 4.0 license This license means that you are free to: Share: copy and redistribute the material in any medium or format Adapt: remix, transform, and build upon the material for any purpose, even commercially. The licensor cannot revoke these freedoms as long as you follow the license terms. Under the following terms: Attribution: You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. ShareAlike: If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original. No additional restrictions: You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits. 0.1.3 Copying the lab manual This lab manual was written in R-Studio, using R Markdown, and compiled into a web-book format using the bookdown package. All of the source code for this book is available in a GitHub repository: https://github.com/erinmaz/statisticsLab In addition, the source code for project this book was based on can be found at: https://github.com/CrumpLab/statisticsLab In principle, anybody could fork or otherwise download this repository. Load the Rproj file in R-studio, and then compile the entire book. Then, the individual .rmd files for each chapter could be edited for content and style to better suit your needs. If you want to contribute to this version of the lab manual, you could make pull requests on GitHub, or discuss issues and request on the issues tab. 0.1.4 Acknowledgments Thanks to the librarians at Brooklyn College of CUNY, especially Miriam Deutch, and Emily Fairey, for their support throughout the process. Thanks to CUNY for supporting OER development, and for the grant we received to develop this work. Development of version 2.0 (described above) was funded by the Council of Atlantic University Libraries through an AtlanticOER Development Grant awarded to Erin Mazerolle, Christine Lomore, Margaret Vail, Derrick Lee, Sherry Neville-MacLean, and Lindsay Berrigan. "],["software.html", "Software 0.2 Data 0.3 R 0.4 Excel 0.5 SPSS 0.6 JAMOVI", " Software 0.2 Data Data files used for the labs are all taken from open data sources. Links are provided for each lab. For convenience, all of the data files are also available here as single files in the github repository for this lab manual 0.2.1 Data Repository https://github.com/CrumpLab/statisticsLab/tree/master/data 0.2.2 CSV format All of the data files in .csv format are also available to download as a .zip file 0.2.3 SPSS format All of the data files in SPSS format are also available to download as a .zip file 0.3 R In this course we will be using R as a tool to analyze data, and as a tool to help us gain a better understanding of what our analyses are doing. Throughout each lab we will show you how to use R to solve specific problems, and then you will use the examples to solve homework and lab assignments. R is a very deep programming language, and in many ways we will only be skimming the surface of what R can do. Along the way, there will be many pointers to more advanced techniques that interested students can follow to become experts in using R for data-analysis, and computer programming in general. R is primarily a computer programming language for statistical analysis. It is free, and open-source (many people contribute to developing it), and runs on most operating systems. It is a powerful language that can be used for all sorts of mathematical operations, data-processing, analysis, and graphical display of data. I even used R to write this lab manual. And, I use R all the time for my own research, because it makes data-analyis fast, efficient, transparent, reproducible, and exciting. Statistics Software SPSS SAS JMP R Julia Matlab 0.3.1 Why R? There are lots of different options for using computers to analyze data, why use R?. The options all have pros and cons, and can be used in different ways to solve a range of different problems. Some software allows you to load in data, and then analyze the data by clicking different options in a menu. This can sometimes be fast and convenient. For example, once the data is loaded, all you have to do is click a couple buttons to analyse the data! However, many aspects of data-analysis are not so easy. For example, particular analyses often require that the data be formatted in a particular way so that the program can analyze it properly. Often times when a researcher wants to ask a new question of an existing data set, they have to spend time re-formatting the data. If the data is large, then reformatting by hand is very slow, and can lead to errors. Another option, is to use a scripting language to instruct the computer how reformat the data. This is very fast and efficient. R provides the ability to everything all in one place. You can load in data, reformat it any way you like, then anlayze it anyway you like, and create beautiful graphs and tables (publication quality) to display your findings. Once you get the hang of R, it becomes very fast and efficient. 0.3.2 Installing R and R Studio Download and install R onto your computer. The R website is: http://www.r-project.org Find the download R using the link. This will take you to a page with many different mirror links. You can click any of these links to download a version of R that will work on your computer. After you have installed R you can continue. After you have installed R on your computer, you should want to install another program called R studio. This program provides a user-friendly interface for using R. You must already have installed R before you perform this step. The R-studio website is: http://www.rstudio.com Find the download link on the front-page, and then download R studio desktop version for your computer. After you have installed R studio you will be ready to start using R. The website R-fiddle allows you to run R scripts in the cloud, so you can practice R from your web-browser! 0.3.3 R studio notes and tips Figure 0.1: The R-studio workspace 0.3.3.1 Console When you open up R studio you will see three or four main windows (the placement of each are configurable). In the above example, the bottom left window is the command line (terminal or console) for R. This is used to directly enter commands into R. Once you have entered a command here, press enter to execute the command. The console is useful for entering single lines of code and running them. Oftentimes this occurs when you are learning how to correctly execute a line of code in R. Your first few attempts may be incorrect resulting in errors, but trying out different variations on your code in the command line can help you produce the correct code. Pressing the up arrow while in the console will scroll through the most recently executed lines of code. 0.3.3.2 Script Editor The top left corner contains the script editor. This is a simple text editor for writing and saving R scripts with many lines. Several tabs can be opened at once, with each tab representing a different R script. R scripts can be saved from the editor (resulting in a .r file). Whole scripts can be run by copy and pasting them into the console and pressing enter. Alternatively, you can highlight portions of the script that you want to run (in the script editor) and press command-enter to automatically run that portion in the console (or press the button for running the current line/section: green arrow pointing right). 0.3.3.3 Workspace and History The top right panel contains two tabs, one for the workspace and another for history. The workspace lists out all of the variables and functions that are currently loaded in R’s memory. You can inspect each of the variables by clicking on them. This is generally only useful for variables that do not contain large amounts of information. The history tab provides a record of the recent commands executed in the console. 0.3.3.4 File, Plot, Packages, Help The bottom-right window has four tabs for files, plots, packages, and help. The files tab allows browsing of the computers file directory. An important concept in R is the current working directory. This is file folder that R points to by default. Many functions in R will save things directly to this direct, or attempt to read files from this directory. The current working directory can be changed by navigating to the desired folder in the file menu, and then clicking on the more option to set that folder to the current working directory. This is especially important when reading in data to R. The current working directory should be set to the folder containing the data to be inputted into R. The plots tab will show recent plots and figures made in R. The packages tab lists the current R libraries loaded into memory, and provides the ability to download and enable new R packages. The help menu is an invaluable tool. Here, you can search for individual R commands to see examples of how they are used. Sometimes the help files for individual commands are opaque and difficult to understand, so it is necessary to do a Google search to find better examples of using these commands. 0.3.4 How to complete the R Labs Each of the labs focuses on particular data-analysis problems, from graphing data, computing descriptive statistics, to running inferential tests in R. All of the labs come in three parts, a training part, a generalization part, and a writing part. The training part includes step-by-step examples of R code that solves particular problems. The R code is always highlighted in grey. The generalization part gives short assignments to change parts of the provided code to solve a new problem. The writing part tasks you with answering questions about statitiscal concepts. The way to complete each lab is to open a new R Markdown document in R-studio, and then document your progression through each of the parts. By doing this, you will become familiar with how R and R-studio works, and how to create documents that preserve both the code and your notes all in one place. There are a few tricks to getting started that are outline below. Open R-studio 0.3.4.1 R projects Create a new R project Go to the file menu and select new project, or go to the top right-hand corner of R-studio, you should see a blue cube with an R in it, then select New project from the dropdown menu Save the new R project somewhere that you can find it. If you are working on a lab computer, then save the new R project to the desktop. What is an R project? When you create a new R project you are creating two things, 1) a new folder on your computer, and 2) a “.Rproj” file. For example, if you gave your R project the name “Lab1,” then you will have created a folder title “Lab1,” and inside the folder you will find an R project file called “Lab1.Rproj.” As you work inside R-studio you will be creating text documents, and you will be doing things like loading data, and saving the results of your analyses. As your work grows and becomes more complex, you can often find yourself creating many different files. The R project folder is a very useful way of organizing your files all in one place so you can find them later. If you double-clik an R project file, R-studio will automatically load and restore your last session. In the labs, you will be using your R project folder to: save data files into this folder save R-markdown files that you will use to write your R-code and lab notes save the results of your analysis 0.3.4.2 Installing libraries When you install R and R-studio, you get what is called Base R. Base R contains many libraries that allow you to conduct statistical anlayses. Because R is free and open-source, many other developers have created add-on libraries that extend the functionality of R. We use some of these libraries, and you need to install them before you can do the labs. For example, in any of the labs, whenever you see a line code that uses the word library like this library(libraryname), this line of code telling R to load up that library so it can be used. The libraryname would be replaced with the actual name of the library. For example, you will see code like this in the labs: library(data.table) This line of code is saying that the data.table library needs to be loaded. You can check to see if any library is already loaded by clicking on the “packages” tab in the bottom right hand panel. You will see many packages listed in alphabetical order. Packages that are currently loaded and available have a checkmark. If you scroll down and find that you do not have data.table installed, then you need to install it. To install any package follow these steps: Click on the packages tab Find the “install” button in the top left hand corner of the packages tab. Click the install button Make sure “install from:” is set to CRAN repository Make sure “dependencies” is clicked on (with a checkmark) type the name of the library into the search bar. As you type, you should see the names of different packages you can install pop-up in a drop-down menu. You must be connected to the internet to install packages from CRAN Once you find the package (e.g., data.table), click it, or just make sure the full, correctly spelled name, is in the search bar Press the install button You should see some text appear in the console while R installs the package. After you have installed the package, you should now see that it is listed in the packages tab. You can turn the package on by clicking it in the package tab. OR, you can turn the packge on by running the command library(data.table) in the console, to do this type library(data.table) into the console, and press enter. 0.3.4.3 Quick install If you are using R on one of the lab computers, you may find that some of the packages are not installed. The lab computers get wiped everynight, so it may be necessary to install packages each time you come back to the lab. Fortunately, we can tell R to install all of the packages we need in one go. Copy the following lines of code into the console, and press enter. Note you can select all of the lines at once, then copy them, then paste all of them into the console, and press enter to run them all. After each of the packages are installed, you will then be able to load them using library(). install.packages(ggplot2) install.packages(dplyr) install.packages(data.table) install.packages(summarytools) install.packages(gapminder) install.packages(ggpubr) 0.3.4.4 R markdown Once you have the necessary packages installed you can begin creating R markdown documents for each lab. We admit that at the beginning, R markdown documents might seem a little bit confusing, but you will find they are extremely useful and flexible. Basically, what R markdown allows you to do is combine two kinds of writing, 1) writing R code to conduct analyses, and 2) writing normal text, with headers, sub-headers, and paragraphs. You can think of this like a lab journal, that contains both your writing about what you are doing (e.g., notes to self), and the code that you use for analysis. Additionally, when your code does something like make a graph, or run a statistical test, you can ask R markdown to print the results. The R markdown website has an excellent tutorial that is well worth your time to check out: https://rmarkdown.rstudio.com/lesson-1.html 0.3.4.5 R markdown lab templates We have created a set of template documents for each lab that can be downloaded here: download lab templates. When you unzip the file you should find the following: A new folder titled “RMarkdownsLab” Inside the folder you will see the “RMarkdownsLab.Rproj” file A data folder containing data files for the labs A “LabTemplates” folder containing the R markdown templates for each lab. To get started with Lab 1, follow these steps: copy the template file for lab 1, “Lab 01 Graphing_Student Name.Rmd,” and place it into the “RMarkdownsLab” (copy it out of the template folder, and into the RMarkdownsLab folder). Rename the file to add your own name, eg., “Lab1GraphingMattCrump.Rmd” double-click the “RMarkdownsLab.Rproj” file R-studio will now load up. If you click the files tab, you will see all of the files and folders inside the “RMarkdownsLab” folder Click on your lab1 .rmd file, it will now load into the editor window. Each lab template .rmd file contains three main sections, one for each part of the lab. You will write things inside each section to complete the lab. 0.3.5 Screencast tutorial Follow this guide to get up running for Lab 1. 0.3.6 R-studio Cloud R-studio is also in the cloud. This means that if you want to use R and R-studio through your web-browser you can do that without even installing R or R-studio on your computer. It’s also free! sign up for an R-studio cloud account here: https://rstudio.cloud You can make new R projects, work inside them, and everything is saved in the cloud! To see how everything would work, follow the steps in this video. You will need to download this .zip file to your computer to get started The link to the video is https://www.youtube.com/watch?v=WsbnV0t7FE4, or you can watch it here: 0.4 Excel 0.5 SPSS In this course, we will be using SPSS to help us with the analyses about which we are learning in classes. Throughout each lab, we will show you how to use SPSS to solve specific problems, and then you will use the examples to solve in-lab assignments, homework, and the analysis for your team project. 0.5.1 Installing SPSS We will be using SPSS version 27. The file to download and installation instructions can be found here: https://stfx.teamdynamix.com/TDClient/1764/Portal/KB/ArticleDet?ID=44882 0.5.2 Notes and Tips 0.5.2.1 Discrepancies in Visuals Throughout the lab manual, you will encounter visuals of screens in SPSS. If an image looks slightly different from what you observe on your screen, the discrepancy may be due to a difference in version (27 vs older versions) or operating system (Mac vs PC). Most images are not from version 27 – which was made available to us in January of 2021. From time to time, you may notice that the layout of a pop-up window or the set of commands for an analysis differs for you. A difference in layout is likely due to the difference in our operating systems. The difference in the set of commands may be slight and based on our operating systems, or it may be just a matter of there being more than one correct way to accomplish the same task. If you encounter a difference, let us know so that we can share it with other students and update this manual. 0.5.2.2 Hidden Toolbars If the toolbar is hidden when you enter SPSS, you can select View, Toolbars, and Data Editor to access the images used for shortcuts. Figure 0.2: View without Shortcuts Figure 0.3: View with Shortcuts ####Adjusting the Font Size The default font size in SPSS files is small for many readers. If you would like to increase the size of the font in the data file, please click View and Fonts to adjust the font for your preferences. Increasing the size of the font in the output file seems a bit more complicated. You can increase the size of the font in the output pane easily by clicking View and Outline Size; however, the font within the main section of the file is not so easily changed. To increase the size of the tables generated, please click Edit and Options and select the Pivot Tables tab. Within the pop-up window (shown below), change from System Default to Large Font (click to highlight this option) and click OK. 0.5.3 Opening SPSS and the SPSS layout Your lab instructor will take you through the process of opening the SPSS program. You may double-click on its icon located on the desktop of your lab computer, or you may find it using the Start menu. Once the program loads, you will be prompted with a pop-up window that asks you which file you would like to open. For now, we will be examining the basic layout of SPSS without a data set, so you can click Cancel. Once you do, the main SPSS spreadsheet should open. It will look like this, a basic spreadsheet: Figure 0.4: Empty SPSS spreadsheet Notice at the bottom of your window there are two tabs; “Data View” and “Variable View.” In data view, we enter data into our spreadsheet. You will notice that rows are numbered on the left-hand side of the spreadsheet, while columns are labeled “var.” This is an indication of the general structure of SPSS: Variables are contained in the columns, and rows indicate individual observations. For example, if you obtained the heights (in inches) of 5 people {x= 64, 70, 63, 62, 65} and wanted to enter their data into SPSS, each person’s height would be entered in a new row, not across the columns, as seen below: 0.5.3.1 Reviewing variable properties and the Variable View tab Now that we have some data entered, we might want to name our variable so that it’s evident our measurements represent heights. In order to view or modify variable names and other properties, look to the bottom of your SPSS window and switch over to the “Data View” tab. Once you do this, your window will appear as follows: Here, you can edit the name of your variables, and specify their properties. Variable names can be anything you like, with the restriction that you cannot use numbers or spaces. Next, notice several other important properties of variables you may at some point need to set or modify: Name: the name of your variable that will appear as a colum header in Data View. No spaces or numerals. Type: Your data will most often be Numeric, but sometimes, as in data representing currency or data in scientific notation, you may change the data type appropriately. If your data is simply a label, word, or response (such as an open-ended response to a survey question), choose “String”: this tells SPSS not to treat this variable as a number. (Nota bene: if you select the wrong type of variable, SPSS may not be able to process your requested calculations, so always remember to check this parameter!) Width: This refers to how many digits will be visible by default. Decimals: This refers to how many decimal places will be visible by default. Label: This is a description of the variable. Any information too long to be included in the variable name goes here. Values: For nominal scale data, let’s say 1 represents male and 2 represents female, this is where you include the values and their corresponding labels. Measure: This variable property allows you to specify the nature of your data. Depending on the kind of scale you are using, you will choose a different measure type. Nominal and ordinal are chosen for nominal and ordinal scales, respectively. “Scale” is used when your data is measured on a ratio or interval scale. 0.5.4 Practice Problems In your assigned breakout room, collect information to use in a data file. For each member of your group, collect preferred name, year of study (1, 2, 3, etc.), and type of personal device used (Mac, PC, Chromebook, etc.). Remember to check the settings of the variables in Variable View. You should each create an SPSS data file with the collected information, and upload that file in Moodle under the “SPSS Basics – Data File Submission” link. A data file has been provided for you in Moodle. Open that file and answer the questions in the Moodle quiz entitled “Reading an SPSS Data File.” 0.6 JAMOVI "]]
=======
[["lab-3-correlation.html", "Chapter 3 Lab 3: Correlation 3.1 General Goals 3.2 R 3.3 Excel 3.4 SPSS 3.5 JAMOVI", " Chapter 3 Lab 3: Correlation If  we choose a group of social phenomena with no antecedent knowledge of the causation or absence of causation among them, then the calculation of correlation coefficients, total or partial, will not advance us a step toward evaluating the importance of the causes at work. Sir Ronald Fisher In lecture and in the textbook, we have been discussing the idea of correlation. This is the idea that two things that we measure can be somehow related to one another. For example, your personal happiness, which we could try to measure say with a questionnaire, might be related to other things in your life that we could also measure, such as number of close friends, yearly salary, how much chocolate you have in your bedroom, or how many times you have said the word Nintendo in your life. Some of the relationships that we can measure are meaningful, and might reflect a causal relationship where one thing causes a change in another thing. Some of the relationships are spurious, and do not reflect a causal relationship. In this lab you will learn how to compute correlations between two variables in software, and then ask some questions about the correlations that you observe. 3.1 General Goals Compute Pearsons r between two variables using software Discuss the possible meaning of correlations that you observe 3.1.1 Important Info We use data from the World Happiness Report. A .csv of the data can be found here: WHR2018.csv 3.2 R In this lab we use explore to explore correlations between any two variables, and also show how to do a regression line. There will be three main parts. Getting r to compute the correlation, and looking at the data using scatter plots. Well look at some correlations from the World Happiness Report. Then youll look at correlations using data we collect from ourselves. It will be fun. 3.2.1 cor for correlation R has the cor function for computing Pearsons r between any two variables. In fact this same function computes other versions of correlation, but well skip those here. To use the function you just need two variables with numbers in them like this: x &lt;- c(1,3,2,5,4,6,5,8,9) y &lt;- c(6,5,8,7,9,7,8,10,13) cor(x,y) ## [1] 0.76539 Well, that was easy. 3.2.1.1 scatterplots Lets take our silly example, and plot the data in a scatter plot using ggplot2, and lets also return the correlation and print it on the scatter plot. Remember, ggplot2 wants the data in a data.frame, so we first put our x and y variables in a data frame. library(ggplot2) # create data frame for plotting my_df &lt;- data.frame(x,y) # plot it ggplot(my_df, aes(x=x,y=y))+ geom_point()+ geom_text(aes(label = round(cor(x,y), digits=2), y=12, x=2 )) Wow, were moving fast here. 3.2.1.2 lots of scatterplots Before we move on to real data, lets look at some fake data first. Often we will have many measures of X and Y, split between a few different conditions, for example, A, B, C, and D. Lets make some fake data for X and Y, for each condition A, B, C, and D, and then use facet_wrapping to look at four scatter plots all at once x&lt;-rnorm(40,0,1) y&lt;-rnorm(40,0,1) conditions&lt;-rep(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;), each=10) all_df &lt;- data.frame(conditions, x, y) ggplot(all_df, aes(x=x,y=y))+ geom_point()+ facet_wrap(~conditions) 3.2.1.3 computing the correlations all at once Weve seen how we can make four graphs at once. Facet_wrap will always try to make as many graphs as there are individual conditions in the column variable. In this case there are four, so it makes four. Notice, the scatter plots dont show the correlation (r) values. Getting these numbers on there is possible, but we have to calculate them first. Well leave it to you to Google how to do this, if its something you want to do. Instead, what we will do is make a table of the correlations in addition to the scatter plot. We again use dplyr to do this: OK, we are basically ready to turn to some real data and ask if there are correlations between interesting variablesYou will find that there are some But before we do that, we do one more thing. This will help you become a little bit more skeptical of these correlations. 3.2.1.4 Chance correlations As you learned from the textbook. We can find correlations by chance alone, even when there is no true correlation between the variables. For example, if we sampled randomly into x, and then sampled some numbers randomly into y. We know they arent related, because we randomly sampled the numbers. However, doing this creates some correlations some of the time just by chance. You can demonstrate this to yourself with the following code. Its a repeat of what we already saw, jut with a few more conditions added. Lets look at 20 conditions, with random numbers for x and y in each. For each, sample size will be 10. Well make the fake data, then make a big graph to look at all. And, even though we get to regression later in the lab, Ill put the best fit line onto each scatter plot, so you can see the correlations. x&lt;-rnorm(10*20,0,1) y&lt;-rnorm(10*20,0,1) conditions&lt;-rep(1:20, each=10) all_df &lt;- data.frame(conditions, x, y) ggplot(all_df, aes(x=x,y=y))+ geom_point()+ geom_smooth(method=lm, se=FALSE)+ facet_wrap(~conditions)+ theme_classic() ## `geom_smooth()` using formula &#39;y ~ x&#39; You can see that the slope of the blue line is not always flat. Sometimes it looks like there is a correlation, when we know there shouldnt be. You can keep re-doing this graph, by re-knitting your r Markdown document, or by pressing the little green play button. This is basically you simulating the outcomes as many times as you press the button. The point is, now you know you can find correlations by chance. So, in the next section, you should always wonder if the correlations you find reflect meaningful association between the x and y variable, or could have just occurred by chance. 3.2.2 World Happiness Report Lets take a look at some correlations in real data. We are going to look at responses to a questionnaire about happiness that was sent around the world, from the world happiness report 3.2.2.1 Load the data We load the data into a data frame. Reminder, the following assumes that you have downloaded the RMarkdownsLab.zip file which contains the data file in the data folder. library(data.table) whr_data &lt;- fread(&#39;data/WHR2018.csv&#39;) You can also load the data using the following URL library(data.table) whr_data &lt;- fread(&quot;https://raw.githubusercontent.com/CrumpLab/statisticsLab/master/data/WHR2018.csv&quot;) 3.2.2.2 Look at the data library(summarytools) view(dfSummary(whr_data)) You should be able to see that there is data for many different countries, across a few different years. There are lots of different kinds of measures, and each are given a name. Ill show you some examples of asking questions about correlations with this data, then you get to ask and answer your own questions. 3.2.2.3 My Question #1 For the year 2017 only, does a countrys measure for Freedom to make life choices correlate with that countrys measure for \" Confidence in national government\"? Lets find out. We calculate the correlation, and then we make the scatter plot. cor(whr_data$`Freedom to make life choices`, whr_data$`Confidence in national government`) ## [1] NA ggplot(whr_data, aes(x=`Freedom to make life choices`, y=`Confidence in national government`))+ geom_point()+ theme_classic() ## Warning: Removed 167 rows containing missing values (geom_point). Interesting, what happened here? We can see some dots, but the correlation was NA (meaning undefined). This occurred because there are some missing data points in the data. We can remove all the rows with missing data first, then do the correlation. We will do this a couple steps, first creating our own data.frame with only the numbers we want to analyse. We can select the columns we want to keep using select. Then we use filter to remove the rows with NAs. library(dplyr) smaller_df &lt;- whr_data %&gt;% select(country, `Freedom to make life choices`, `Confidence in national government`) %&gt;% filter(!is.na(`Freedom to make life choices`), !is.na(`Confidence in national government`)) cor(smaller_df$`Freedom to make life choices`, smaller_df$`Confidence in national government`) ## [1] 0.4080963 Now we see the correlation is .408. Although the scatter plot shows the dots are everywhere, it generally shows that as Freedom to make life choices increases in a country, that countrys confidence in their national government also increase. This is a positive correlation. Lets do this again and add the best fit line, so the trend is more clear, we use geom_smooth(method=lm, se=FALSE). I also change the alpha value of the dots so they blend it bit, and you can see more of them. # select DVs and filter for NAs smaller_df &lt;- whr_data %&gt;% select(country, `Freedom to make life choices`, `Confidence in national government`) %&gt;% filter(!is.na(`Freedom to make life choices`), !is.na(`Confidence in national government`)) # calcualte correlation cor(smaller_df$`Freedom to make life choices`, smaller_df$`Confidence in national government`) ## [1] 0.4080963 # plot the data with best fit line ggplot(smaller_df, aes(x=`Freedom to make life choices`, y=`Confidence in national government`))+ geom_point(alpha=.5)+ geom_smooth(method=lm, se=FALSE)+ theme_classic() ## `geom_smooth()` using formula &#39;y ~ x&#39; 3.2.2.4 My Question #2 After all that work, we can now speedily answer more questions. For example, what is the relationship between positive affect in a country and negative affect in a country. I wouldnt be surprised if there was a negative correlation here: when positive feelings generally go up, shouldnt negative feelings generally go down? To answer this question, we just copy paste the last code block, and change the DVs to be Positive affect, and Negative affect # select DVs and filter for NAs smaller_df &lt;- whr_data %&gt;% select(country, `Positive affect`, `Negative affect`) %&gt;% filter(!is.na(`Positive affect`), !is.na(`Negative affect`)) # calcualte correlation cor(smaller_df$`Positive affect`, smaller_df$`Negative affect`) ## [1] -0.3841123 # plot the data with best fit line ggplot(smaller_df, aes(x=`Positive affect`, y=`Negative affect`))+ geom_point(alpha=.5)+ geom_smooth(method=lm, se=FALSE)+ theme_classic() ## `geom_smooth()` using formula &#39;y ~ x&#39; Bam, there we have it. As positive affect goes up, negative affect goes down. A negative correlation. 3.2.3 Generalization Exercise This generalization exercise will explore the idea that correlations between two measures can arise by chance alone. There are two questions to answer. For each question you will be sampling random numbers from uniform distribution. To conduct the estimate, you will be running a simulation 100 times. The questions are: Estimate the range (minimum and maximum) of correlations (using pearonss r) that could occur by chance between two variables with n=10. Estimate the range (minimum and maximum) of correlations (using pearonss r) that could occur bychance between two variables with n = 100. Use these tips to answer the question. Tip 1: You can use the runif() function to sample random numbers between a minimum value, and maximum value. The example below sample 10 (n=10) random numbers between the range 0 (min = 0) and 10 (max=10). Everytime you run this code, the 10 values in x will be re-sampled, and will be 10 new random numbers x &lt;- runif(n=10, min=0, max=10) Tip 2: You can compute the correlation between two sets of random numbers, by first sampling random numbers into each variable, and then running the cor() function. x &lt;- runif(n=10, min=0, max=10) y &lt;- runif(n=10, min=0, max=10) cor(x,y) ## [1] -0.3059606 Running the above code will give different values for the correlation each time, because the numbers in x and y are always randomly different. We might expect that because x and y are chosen randomly that there should be a 0 correlation. However, what we see is that random sampling can produce fake correlations just by chance alone. We want to estimate the range of correlations that chance can produce. Tip 3: One way to estimate the range of correlations that chance can produce is to repeat the above code many times. For example, if you ran the above code 100 times, you could save the correlations each time, then look at the smallest and largest correlation. This would be an estimate of the range of correlations that can be produced by chance. How can you repeat the above code many times to solve this problem? We can do this using a for loop. The code below shows how to repeat everything inside the for loop 100 times. The variable i is an index, that goes from 1 to 100. The saved_value variable starts out as an empty variable, and then we put a value into it (at index position i, from 1 to 100). In this code, we put the sum of the products of x and y into the saved_value variable. At the end of the simulation, the save_value variable contains 100 numbers. The min() and max() functions are used to find the minimum and maximum values for each of the 100 simulations. You should be able to modify this code by replacing sum(x*y) with cor(x,y). Doing this will allow you to run the simulation 100 times, and find the minimum correlation and maximum correlation that arises by chance. This will be estimate for question 1. To provide an estimate for question 2, you will need to change n=10 to n=100. saved_value &lt;- c() #make an empty variable for (i in 1:100){ x &lt;- runif(n=10, min=0, max=10) y &lt;- runif(n=10, min=0, max=10) saved_value[i] &lt;- sum(x*y) } min(saved_value) ## [1] 113.0171 max(saved_value) ## [1] 517.7462 3.2.4 Writing assignment Answer the following questions with complete sentences. When you have finished everything. Knit the document and hand in your stuff (you can submit your .RMD file to blackboard if it does not knit.) Imagine a researcher found a positive correlation between two variables, and reported that the r value was +.3. One possibility is that there is a true correlation between these two variables. Discuss one alternative possibility that would also explain the observation of +.3 value between the variables. Explain the difference between a correlation of r = .3 and r = .7. What does a larger value of r represent? Explain the difference between a correlation of r = .5, and r = -.5. 3.3 Excel How to do it in Excel 3.4 SPSS In this lab, we will use SPSS to calculate the correlation coefficient. We will focus on the most commonly used Pearsons coefficient, r. We will learn how to: Calculate the Pearsons r correlation coefficient for bivariate data Produce a correlation matrix, reporting Pearsons r for more than two variables at a time Produce a scatterplot Split a data file for further analysis Lets first begin with a short data set we will enter into a new SPSS data spreadsheet. Remember, in order to calculate a correlation, you need to have bivariate data; that is, you must have at least two variables, x and y. You can have more than two variables, in which case we can calculate a correlation matrix, as indicated in the section that follows. 3.4.1 Correlation Coefficient for Bivariate Data: Two Variables Lets use the following data set: {x= 1, 3, 2, 5, 4, 6, 5, 8, 9} {y= 6, 5, 8, 7, 9, 7, 8, 10, 13}. Notice there are two variables, x and y. Enter these into SPSS and name them appropriately. Next, click Analyze, then Correlate, then Bivariate: The next window will ask you to select variables to correlate. Since we have two (x and y) move them both from the left-hand field to the right-hand field using the arrow. Notice that in this window, Pearson is selected. This is the default setting (and the one we want), but notice there are other ways to calculate the correlation between variables. We will stick with Pearsons correlation coefficient for this course. Now, click OK. SPSS will produce an output table containing the correlation coefficient requested. Notice that the table is redundant; it gives us the correlation between x and y, the correlation between y and x, the correlation between x and itself, and the correlation between y and itself. Any variable correlated with itself will result in an r of 1. The Pearson r correlation between variables x and y is .765. 3.4.2 Correlation Matrix In the event that you have more than two variables in your spreadsheet, and would like to evaluate correlations between several variables taken two at a time, you need not re-run the correlations in SPSS repeatedly. You can, in fact, enter multiple variables into the correlation window and obtain a correlation matrixa table showing every possible bivariate correlation amongst a group of variables. To illustrate how this is done, lets add a new variable to our existing spreadsheet: variable z, {z= 1, 4, 2, 9, 5, 7, 12, 5, 3} From here, go to Analyze, then Correlate, then Bivariate: Next, you will encounter the window that asks you to indicate which variables to correlate. Select all three variables (x, y, and z) and move them to the right-hand field using the arrow. Click OK. SPSS will produce an output table that contains correlations for every pairing of our three variables, along with the correlations of each variable with itself. According to this output: The correlation coefficient between variables x and y is .765 The correlation coefficient between variables x and z is .294 The correlation coefficient between variables y and z is -.080 3.4.3 Correlation and Scatterplots To accompany the calculation of the correlation coefficient, the scatterplot is the relevant visualization tool. Lets use data from The World Happiness Report, a questionnaire about happiness. Here is a link to the file named WHR2018.sav. Using this data, lets answer the following question: does a countrys measure for Freedom to make life choices correlate with that countrys measure for Confidence in national government? Lets find the correlation coefficient between these variables first. Go to Analyze, then Correlate, then Bivariate: Next, a window will appear asking for the variables to be correlated. Go through the list on the left and find Freedom to make life choices as well as Confidence in national government. Move both of these variables to the field on the right using the arrow. Click OK. SPSS will produce a correlation table. Based on this output, the correlation between Freedom to make life choices and Confidence in national government is .408. Lets continue to create the scatterplot for this data. Go to Graphs, then Legacy Dialogs, then Scatter In the next window, choose Simple, then Define: Next, move your two variables (Freedom to make life choices and Confidence in national government) into the x-axis and y-axis fields. Again, it does not matter which variable goes where, for now. Click OK. SPSS will produce a scatterplot of your data, as follows: You can keep this scatterplot as it is, or, you can edit it to include a straight line that best fits the data points. This line is known as the best-fitting line as it minimizes the distance from it to all the data. To edit the scatterplot double click on the graph and a window labeled Chart Editor should appear: In this window, find the button at the top that reads Fit Line at Total when you hover your mouse over it. Below, I have highlighted it for clarity: Press this button and you will see a new menu. Make sure Linear is selected and click Apply. Next, exit from the Chart Editor. This means you will hit the X in the corner of the window. You will find that the graph in your output window has now updated and has a line drawn on it. This scatterplot is very important. The distance between the line and the data points is indicative of the strength of the correlation coefficient; they are directly related. For example, if the data were more clustered or tighter to the line, the correlation would be stronger. If the data points are more spread out and far from the line, the correlation is weaker. 3.4.4 Splitting a File What if we asked the question: for the year 2017 only, does a countrys measure for Freedom to make life choices correlate with that countrys measure for Confidence in national government? Notice that this question is asking us to find the correlation between the same two variables we used in the previous example, but only in the case where the year is 2017. To acheive this, were going to utilize a function called splitting. Splitting takes the file as a whole, and sets it up so that every analysis is done on some subset of the data. For example, if we split our data by year and calculate a correlation coefficient, SPSS will find Pearson r for only 2017, and another for only 2016, and so on. In order to split the data, we go to the top menu and choose Data, then Split file In the next window, you must select Organize output by groups and then specify which variable will be used to split the data. Select year and move it to the right-hand field using the arrow. Click OK. Notice that this will cause the output window to produce some text indicating that you have split your file. You can ignore this and go back to your data window. From here, any analysis you choose to do will be done separately for each years worth of data. Lets calculate the correlation coefficient, as usual. Click Analyze, then Correlate, then Bivariate: In the next window, select the variables to be used (they will be the same as in the last example). Click OK. Notice that in the output window you will see a bunch of correlation tables (13 of them to be exact), one for each year. Scroll down and find the table with the heading year = 2017. Thats the table we need in order to answer our question: This table indicates that, if we only look at the year 2017, the correlation coefficient between Freedom to make life choices and Confidence in national government is .442. It is VERY important to remember that once you have split a file, every analysis that follows the split will be done on the split variable. If you want to go back to performing analyses and calculating statistics for the data as a whole, you must UNSPLIT your data file (or undo the split). To do this, go to Data, then Split file Then make sure to select Analyze all cases, do not create groups and click OK. 3.4.5 Practice Problems For the year 2005 ONLY, find the correlation between perceptions of corruption and positive affect. Create a scatterplot to visualize this relationship. What are your conclusions about the relationship between affect and perceived corruption? Is this surprising to you? What has happened to log GDP (consider this a measure of GDP) in the United States ONLY with time (as the year has increased)? Explain this relationship and provide a scatterplot. Which country (or countries) have seen a more consistent and strong increase in log GDP over time? Which country (or countries) have seen a decrease over time? 3.5 JAMOVI This section is copied almost verbatim, with some editorial changes, from Answering questions with data: The lab manual for R, Excel, SPSS and JAMOVI, Lab 3, Section 3.4, SPSS, according to its CC license. Thank you to Crump, Krishnan, Volz, &amp; Chavarga (2018). In this lab, we will use jamovi to calculate the correlation coefficient. We will focus on the most commonly used Pearsons coefficient, r. We will learn how to: Calculate the Pearsons r correlation coefficient for bivariate data Produce a correlation matrix, reporting Pearsons r for more than two variables at a time Produce a scatterplot Applying a filter to the data set for further analysis Lets first begin with a short data set we will enter into a new jamovi data spreadsheet. Remember, in order to calculate a correlation, you need to have bivariate data; that is, you must have at least two variables, x and y. You can have more than two variables, in which case we can calculate a correlation matrix, as indicated in the section that follows. 3.5.1 Correlation Coefficient for Bivariate Data: Two Variables Lets use the following data set: {x= 1, 3, 2, 5, 4, 6, 5, 8, 9} {y= 6, 5, 8, 7, 9, 7, 8, 10, 13}. Notice there are two variables, x and y. Enter these into jamovi, name them appropriately, and be sure to indicate, in the Analyze, that these data are measured on a continuous scale. (REMEMBER: One assumption of Pearsons correlation is that the variables are measured on at least an interval scale. That means you should not use Pearsons correlation with variables that are measured on an ordinal scale. Spearmans correlation may be helpful if you have variables measured on an ordinal scale.) Remember to use the upward facing arrow or the Settings button to close the Analyze pop-up window. Next, click Analyses, Regression, and Correlation Matrix: In the pop-up window, you will select variables to correlate. Since we have two (x and y) move them both from the left-hand field to the right-hand field by highlighting them and using the arrow. Notice that in this window, Pearson is selected. This is the default setting (and the one we want), but notice there are other ways to calculate the correlation between variables. We will stick with Pearsons correlation coefficient for now. In the Results panel on the left, jamovi will produce an output table containing the correlation coefficient requested. (If you are familiar with SPSS, you may notice that the jamovi table is unlike the SPSS table in that the jamovi correlation matrix does not have the redundant information in the top and bottom triangles of the matrix; jamovi gives us only the correlation between x and y in the bottom portion of the table. Note: Any variable correlated with itself will result in an r of 1.) The Pearson r correlation between variables x and y is .765. 3.5.2 Correlation Matrix In the event that you have more than two variables in your spreadsheet, and would like to evaluate correlations between several variables taken two at a time, you need not re-run the correlations in jamovi repeatedly. You can, in fact, enter multiple variables into the correlation window and obtain a correlation matrixa table showing every possible bivariate correlation amongst a group of variables. To illustrate how this is done, lets add a new variable to our existing spreadsheet: variable z, {z= 1, 4, 2, 9, 5, 7, 12, 5, 3}. From here, go to Analyses, then Regression, and then Correlation Matrix: Next, you will encounter the window that asks you to indicate which variables to correlate. Select all three variables (x, y, and z) by highlighting them, and move them to the right-hand field using the arrow. jamovi will produce an output table in the Results panel to the right that contains correlations for every pairing of our three variables. You should see three correlation coefficients and three associated p-values. According to this output: The correlation coefficient between variables x and y is .765; that is, Pearsons r for variables x and y is .765. The correlation coefficient between variables x and z is .294; Pearsons r for x and z is .294. The correlation coefficient between variables y and z is -.080; Pearsons r for y and z is -.080. To further our understanding of these correlation coefficients, we should also look to the p-values associated with each coefficient to decide if the correlation is significant or non-significant. Pearsons r for variables x and y is .765. The p-value is .02 which is less than a conventional alpha level of .05, so we would consider this result to be significant. We might write: A Pearsons correlation was performed, and variables x and y were found to be significantly correlated, r = .77, p = .02. Pearsons r for x and z is .294. The p-value is .44 which is greater than a conventional alpha level of .05, so we would consider this result to be non-significant. We might write: A Pearsons correlation was performed, and no significant correlation was found between variables x and z, r = .29, p &gt; .05. Pearsons r for y and z is -.080. The p-value is .84 which is greater than a conventional alpha level of .05, so we would consider this result to be non-significant. We might write: A Pearsons correlation was performed, and no significant correlation was found between variables y and z, r = -.08, p &gt; .05. 3.5.3 Correlation and Scatterplots To accompany the calculation of the correlation coefficient, the scatterplot is the relevant visualization tool. Lets use data from EngageNS. Using this data, lets answer the following question: Does Number of hours per week spent working at main job correlate with Home activity participation on a typical day: Playing computer games? Lets find the correlation coefficient between these variables first. Go to Analyses, then Regression, and then Correlation Matrix: Next, a window will appear asking for the variables to be correlated. Use the search function to speed up your identification of those variables. Rather than scrolling through all of the variables in the list on the left, look into the Data Dictionary to find the variable names and search for them. Move both of these variables to the field on the right using the arrow. In the Results panel, jamovi will produce a correlation table. Based on this output, the correlation between WORKHR and HM_CGAME is -.042. The negative sign simply indicates that as the scores on one variable increase, the scores on the other variable decrease; the variables are negatively correlated. Looking at the p-value, we see it is .001, which is less than our commonly used alpha levels. This correlation is significant. We might communicate this information like this: A Pearsons correlation analysis was performed, and a significant negative correlation was found between Number of hours per week spent working at main job and Home activity participation on a typical day: Playing computer games, r = -.04, p = .001. 3.5.3.1 Adding the Scatterplot module to jamovi Before you can request a scatterplot in jamovi, you must add Scatterplot as a module. To do so, click on the addition sign which is white with a blue trim that has the word Modules under the sign. Click jamovi library. Under the Available tab, you should see a module called scatr. Click to INSTALL it. When it is installed, it will appear in your Exploration menu. 3.5.3.2 Getting a visual of the correlation Lets continue to create the scatterplot for this data. Go to Analyses, then Exploration, and then Scatterplot. In the next window, choose Simple, then Define: Next, move your two variables (WORKHR and HM_CGAMES) into the x-axis and y-axis fields. Again, it does not matter which variable goes where, for now. (Remember to use the search function to speed up your search for the variables to include.) In the Results panel, jamovi will produce a scatterplot of your data, as follows: You can keep this scatterplot as it is, or, you can edit it to include a straight line that best fits the data points. This line is known as the best-fitting line as it minimizes the distance from it to all the data. To include the line of best fit, click on Linear under the Regression Line heading. You will find that the graph in your Results panel has now updated and has a line drawn on it. This line of best fit on the scatterplot is barely visible. Typically, the distance between the line and the data points is indicative of the strength of the correlation coefficient; they are directly related. For example, if the data were more clustered or tighter to the line, the correlation would be stronger. If the data points are more spread out and far from the line, the correlation is weaker. In this case, although there are many data points clustered around the line, we also see there are a number of data points that are quite far from the line. This is a moderate correlation. We also see that this negative correlation is depicted by a line that falls to the left (i.e., a line with a negative slope). 3.5.4 Applying a Filter What if we asked the question: For residents of the Antigonish and Guysborough regions only, does Number of hours per week spent working at main job correlate with Home activity participation on a typical day: Playing computer games? Notice that this question is asking us to find the correlation between the same two variables we used in the previous example, but only in the case where the REGION is equal to 4. To achieve this, were going to utilize a function called filtering. Filtering the data set makes only those cases that meet our criteria available for use in the analysis to be run. For example, if we filter our data by region and calculate a correlation coefficient, jamovi will find Pearson r for only Antigonish and Guysborough, and not for other regions. In order to filter the data, we go to the top menu and choose Data and then Filter. In the next window, you must set up the filter; indicate which cases will be used. Under Filter 1, click on the formula editor, the fx button. Double click on the variable name (REGION), and it will be incorporated into the filter. Then, use two equal signs, and enter the code for the region of interest (4). Notice that this will cause a new column in the spreadsheet wherein a green checkmark indicates the case/participant will be included in the analysis and a red x indicates the case/participant will be excluded from the analysis. From here, any analysis you choose to do will be done for only the cases match the filter. Lets calculate the correlation coefficient, as usual. Click Analyses, then Regression, and then Correlation Matrix: In the next window, select the variables to be used (they will be the same as in the last example). Notice that in the output now shows a correlation matrix with different results than you saw when you ran the correlation with the entire data set: This table indicates that, if we only look at the Antigonish-Guysborough region, the correlation coefficient between between WORKHR and HM_CGAME is .012 and the p-value is .80. Comparing this p-value to an alpha level of .05, we would say this correlation is non-significant. Again, you may want to inspect the scatterplot to get a visual representation of this correlation coefficient for the data collected from participants in the Antigonish-Guysborough region. Challenge: Give the creation of this scatterplot a try on your own. See if your graph matches the one depicted below. 3.5.5 Removing the Filter It is VERY important to remember that once you have applied a filter, every analysis will be done on the split variable. If you want to go back to performing analyses and calculating statistics for the data as a whole, you must delete the filter. To do this, you can highlight the column showing the filter in the spreadsheet, go to Data, and then Delete. You will be prompted with a question to verify that you want to delete the filter. Click Yes. 3.5.6 Homework Look at participants reported number of close friends and their reported time spent socializing with friends. Are these scores correlated? If so, report r and whether the correlation is significant or non-signifcant? Apply a filter so that you are looking at only the data for participants whose main activity is going to school (Hint: Use the data dictionary to figure out how participants main activities were coded.). Now, run the same correlation you looked at in #1. Are number of close friends and reported time spent socializing with friends correlated for students? Is the correlation significant? Compare these results to the results in #1. Is the correlation between number of close friends and reported time spent socializing with friends stronger or weaker for students than it is for Nova Scotians? 3.5.7 Practice Problems Use the EngageNS data to answer the following questions: Construct a scatterplot using FRIENDS on the x-axis and SOC_FRND on the y-axis to depict the results you found for the last homework question. Can you run a Pearsons correlation analysis on the following pairs of variables? Why or why not? SEX and SLEEP? COMP_TIME and SLEEP? MAINACT and EDUCAT? Run the correlation analysis for any set(s) of variables you determined to be appropriate for using Pearsons correlation. Report the correlation coefficient. Is it considered statistically significant? Write your results following the APA rules discussed below. Some formatting guidelines for writing results sections: All of the numbers are rounded to two decimal places, but if your p-value was .0001, it would be okay to write p &lt; .001. Italicize symbols such as p and t. There are spaces on either side of =, &gt;, or &lt; symbols. Construct the scatterplot for any set(s) of variables you determined to be appropriate for using Pearsons correlation. What do you notice about the scatterplot? Does the slope increase or decrease? Do the dots closely follow the line of best fit? TBD: questions based on PSYC 291 survey / may want to move some from Lab 7 The follwoing three questions are copied verbatim from Answering questions with data: The lab manual for R, Excel, SPSS and JAMOVI, Lab 3, Section 3.2.4, SPSS, according to its CC license. Thank you to Crump, Krishnan, Volz, &amp; Chavarga (2018). Imagine a researcher found a positive correlation between two variables, and reported that the r value was +.3. One possibility is that there is a true correlation between these two variables. Discuss one alternative possibility that would also explain the observation of +.3 value between the variables. Explain the difference between a correlation of r = .3 and r = .7. What does a larger value of r represent? Explain the difference between a correlation of r = .5, and r = -.5. "]]
>>>>>>> b82a7ca53e6094ead25b5e70cec80691afc80d8e
>>>>>>> Stashed changes
